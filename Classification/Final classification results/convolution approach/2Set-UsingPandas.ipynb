{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Identification using 2 Class of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102.640</td>\n",
       "      <td>112.140</td>\n",
       "      <td>55.575</td>\n",
       "      <td>4.1348</td>\n",
       "      <td>1.2005</td>\n",
       "      <td>0.29900</td>\n",
       "      <td>103.640</td>\n",
       "      <td>113.140</td>\n",
       "      <td>56.575</td>\n",
       "      <td>0.87457</td>\n",
       "      <td>0.77381</td>\n",
       "      <td>0.71383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.630</td>\n",
       "      <td>110.780</td>\n",
       "      <td>53.606</td>\n",
       "      <td>4.4764</td>\n",
       "      <td>1.1947</td>\n",
       "      <td>0.28115</td>\n",
       "      <td>102.630</td>\n",
       "      <td>111.780</td>\n",
       "      <td>54.617</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.79521</td>\n",
       "      <td>0.75612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.980</td>\n",
       "      <td>109.780</td>\n",
       "      <td>51.389</td>\n",
       "      <td>4.5646</td>\n",
       "      <td>1.1368</td>\n",
       "      <td>0.24906</td>\n",
       "      <td>103.980</td>\n",
       "      <td>110.780</td>\n",
       "      <td>52.389</td>\n",
       "      <td>0.84510</td>\n",
       "      <td>0.78767</td>\n",
       "      <td>0.76815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.370</td>\n",
       "      <td>110.890</td>\n",
       "      <td>51.504</td>\n",
       "      <td>4.6491</td>\n",
       "      <td>1.1973</td>\n",
       "      <td>0.25798</td>\n",
       "      <td>102.370</td>\n",
       "      <td>111.890</td>\n",
       "      <td>52.505</td>\n",
       "      <td>0.93628</td>\n",
       "      <td>0.89639</td>\n",
       "      <td>0.85926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.185</td>\n",
       "      <td>67.155</td>\n",
       "      <td>66.681</td>\n",
       "      <td>1.0122</td>\n",
       "      <td>1.0357</td>\n",
       "      <td>1.02410</td>\n",
       "      <td>67.185</td>\n",
       "      <td>68.155</td>\n",
       "      <td>67.681</td>\n",
       "      <td>0.85670</td>\n",
       "      <td>0.93231</td>\n",
       "      <td>0.86471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f1       f2      f3      f4      f5       f6       f7       f8  \\\n",
       "0  102.640  112.140  55.575  4.1348  1.2005  0.29900  103.640  113.140   \n",
       "1  101.630  110.780  53.606  4.4764  1.1947  0.28115  102.630  111.780   \n",
       "2  102.980  109.780  51.389  4.5646  1.1368  0.24906  103.980  110.780   \n",
       "3  101.370  110.890  51.504  4.6491  1.1973  0.25798  102.370  111.890   \n",
       "4   66.185   67.155  66.681  1.0122  1.0357  1.02410   67.185   68.155   \n",
       "\n",
       "       f9      f10      f11      f12  \n",
       "0  56.575  0.87457  0.77381  0.71383  \n",
       "1  54.617  0.90695  0.79521  0.75612  \n",
       "2  52.389  0.84510  0.78767  0.76815  \n",
       "3  52.505  0.93628  0.89639  0.85926  \n",
       "4  67.681  0.85670  0.93231  0.86471  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sony=pd.read_csv(\"./data/Canon_143_conv.csv\")\n",
    "sony.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.208</td>\n",
       "      <td>105.840</td>\n",
       "      <td>42.858</td>\n",
       "      <td>6.52910</td>\n",
       "      <td>1.8116</td>\n",
       "      <td>0.30781</td>\n",
       "      <td>80.208</td>\n",
       "      <td>106.840</td>\n",
       "      <td>43.859</td>\n",
       "      <td>0.85447</td>\n",
       "      <td>0.77848</td>\n",
       "      <td>0.80745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.291</td>\n",
       "      <td>106.430</td>\n",
       "      <td>42.996</td>\n",
       "      <td>6.68600</td>\n",
       "      <td>1.7812</td>\n",
       "      <td>0.29750</td>\n",
       "      <td>81.291</td>\n",
       "      <td>107.430</td>\n",
       "      <td>44.225</td>\n",
       "      <td>0.89141</td>\n",
       "      <td>0.81405</td>\n",
       "      <td>0.82285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.349</td>\n",
       "      <td>96.970</td>\n",
       "      <td>35.675</td>\n",
       "      <td>7.42740</td>\n",
       "      <td>1.7487</td>\n",
       "      <td>0.23681</td>\n",
       "      <td>74.349</td>\n",
       "      <td>97.970</td>\n",
       "      <td>36.677</td>\n",
       "      <td>0.87635</td>\n",
       "      <td>0.83646</td>\n",
       "      <td>0.82346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.140</td>\n",
       "      <td>105.380</td>\n",
       "      <td>36.397</td>\n",
       "      <td>8.52830</td>\n",
       "      <td>1.8231</td>\n",
       "      <td>0.21769</td>\n",
       "      <td>79.140</td>\n",
       "      <td>106.380</td>\n",
       "      <td>37.525</td>\n",
       "      <td>0.93185</td>\n",
       "      <td>0.90865</td>\n",
       "      <td>0.88682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.171</td>\n",
       "      <td>43.542</td>\n",
       "      <td>51.721</td>\n",
       "      <td>0.70633</td>\n",
       "      <td>1.1850</td>\n",
       "      <td>1.68520</td>\n",
       "      <td>41.171</td>\n",
       "      <td>44.542</td>\n",
       "      <td>52.721</td>\n",
       "      <td>0.86081</td>\n",
       "      <td>0.88394</td>\n",
       "      <td>0.82186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1       f2      f3       f4      f5       f6      f7       f8      f9  \\\n",
       "0  79.208  105.840  42.858  6.52910  1.8116  0.30781  80.208  106.840  43.859   \n",
       "1  80.291  106.430  42.996  6.68600  1.7812  0.29750  81.291  107.430  44.225   \n",
       "2  73.349   96.970  35.675  7.42740  1.7487  0.23681  74.349   97.970  36.677   \n",
       "3  78.140  105.380  36.397  8.52830  1.8231  0.21769  79.140  106.380  37.525   \n",
       "4  40.171   43.542  51.721  0.70633  1.1850  1.68520  41.171   44.542  52.721   \n",
       "\n",
       "       f10      f11      f12  \n",
       "0  0.85447  0.77848  0.80745  \n",
       "1  0.89141  0.81405  0.82285  \n",
       "2  0.87635  0.83646  0.82346  \n",
       "3  0.93185  0.90865  0.88682  \n",
       "4  0.86081  0.88394  0.82186  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nikon=pd.read_csv(\"./data/nikkon_143_conv.csv\")\n",
    "nikon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>109.036221</td>\n",
       "      <td>99.485467</td>\n",
       "      <td>72.570639</td>\n",
       "      <td>3356.559486</td>\n",
       "      <td>0.959480</td>\n",
       "      <td>0.507625</td>\n",
       "      <td>110.010699</td>\n",
       "      <td>100.476025</td>\n",
       "      <td>74.124328</td>\n",
       "      <td>0.921387</td>\n",
       "      <td>0.898338</td>\n",
       "      <td>0.863663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.972564</td>\n",
       "      <td>34.672541</td>\n",
       "      <td>40.192357</td>\n",
       "      <td>75894.991398</td>\n",
       "      <td>0.483509</td>\n",
       "      <td>0.403322</td>\n",
       "      <td>40.952231</td>\n",
       "      <td>34.664793</td>\n",
       "      <td>39.710646</td>\n",
       "      <td>0.106328</td>\n",
       "      <td>0.132954</td>\n",
       "      <td>0.159995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.210000</td>\n",
       "      <td>10.736000</td>\n",
       "      <td>0.882130</td>\n",
       "      <td>0.616350</td>\n",
       "      <td>0.130310</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>21.346000</td>\n",
       "      <td>11.736000</td>\n",
       "      <td>3.198200</td>\n",
       "      <td>-0.461420</td>\n",
       "      <td>0.005230</td>\n",
       "      <td>-0.352930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>78.151000</td>\n",
       "      <td>74.032000</td>\n",
       "      <td>42.099000</td>\n",
       "      <td>1.143400</td>\n",
       "      <td>0.655420</td>\n",
       "      <td>0.186650</td>\n",
       "      <td>79.140000</td>\n",
       "      <td>75.032000</td>\n",
       "      <td>43.232000</td>\n",
       "      <td>0.904670</td>\n",
       "      <td>0.876320</td>\n",
       "      <td>0.833540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>107.790000</td>\n",
       "      <td>101.220000</td>\n",
       "      <td>68.024000</td>\n",
       "      <td>1.788700</td>\n",
       "      <td>0.881220</td>\n",
       "      <td>0.441120</td>\n",
       "      <td>108.790000</td>\n",
       "      <td>102.220000</td>\n",
       "      <td>69.202000</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>0.940370</td>\n",
       "      <td>0.910810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>140.590000</td>\n",
       "      <td>125.540000</td>\n",
       "      <td>102.310000</td>\n",
       "      <td>6.414800</td>\n",
       "      <td>1.093200</td>\n",
       "      <td>0.746890</td>\n",
       "      <td>141.590000</td>\n",
       "      <td>126.540000</td>\n",
       "      <td>103.310000</td>\n",
       "      <td>0.976010</td>\n",
       "      <td>0.976490</td>\n",
       "      <td>0.952340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>220.040000</td>\n",
       "      <td>217.320000</td>\n",
       "      <td>211.750000</td>\n",
       "      <td>1810000.000000</td>\n",
       "      <td>3.638000</td>\n",
       "      <td>3.393600</td>\n",
       "      <td>221.040000</td>\n",
       "      <td>218.320000</td>\n",
       "      <td>212.750000</td>\n",
       "      <td>0.998890</td>\n",
       "      <td>0.998640</td>\n",
       "      <td>0.997860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               f1          f2          f3              f4          f5  \\\n",
       "count  569.000000  569.000000  569.000000      569.000000  569.000000   \n",
       "mean   109.036221   99.485467   72.570639     3356.559486    0.959480   \n",
       "std     40.972564   34.672541   40.192357    75894.991398    0.483509   \n",
       "min     20.210000   10.736000    0.882130        0.616350    0.130310   \n",
       "25%     78.151000   74.032000   42.099000        1.143400    0.655420   \n",
       "50%    107.790000  101.220000   68.024000        1.788700    0.881220   \n",
       "75%    140.590000  125.540000  102.310000        6.414800    1.093200   \n",
       "max    220.040000  217.320000  211.750000  1810000.000000    3.638000   \n",
       "\n",
       "               f6          f7          f8          f9         f10         f11  \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  569.000000   \n",
       "mean     0.507625  110.010699  100.476025   74.124328    0.921387    0.898338   \n",
       "std      0.403322   40.952231   34.664793   39.710646    0.106328    0.132954   \n",
       "min      0.000367   21.346000   11.736000    3.198200   -0.461420    0.005230   \n",
       "25%      0.186650   79.140000   75.032000   43.232000    0.904670    0.876320   \n",
       "50%      0.441120  108.790000  102.220000   69.202000    0.949200    0.940370   \n",
       "75%      0.746890  141.590000  126.540000  103.310000    0.976010    0.976490   \n",
       "max      3.393600  221.040000  218.320000  212.750000    0.998890    0.998640   \n",
       "\n",
       "              f12  \n",
       "count  569.000000  \n",
       "mean     0.863663  \n",
       "std      0.159995  \n",
       "min     -0.352930  \n",
       "25%      0.833540  \n",
       "50%      0.910810  \n",
       "75%      0.952340  \n",
       "max      0.997860  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nikon.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>136.630542</td>\n",
       "      <td>127.212857</td>\n",
       "      <td>98.524234</td>\n",
       "      <td>2.182164</td>\n",
       "      <td>0.932241</td>\n",
       "      <td>0.552174</td>\n",
       "      <td>137.492710</td>\n",
       "      <td>128.149285</td>\n",
       "      <td>99.481678</td>\n",
       "      <td>0.893481</td>\n",
       "      <td>0.918244</td>\n",
       "      <td>0.835117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48.221557</td>\n",
       "      <td>42.154986</td>\n",
       "      <td>44.261720</td>\n",
       "      <td>1.291193</td>\n",
       "      <td>0.304138</td>\n",
       "      <td>0.285861</td>\n",
       "      <td>48.083568</td>\n",
       "      <td>42.084343</td>\n",
       "      <td>44.155740</td>\n",
       "      <td>0.097588</td>\n",
       "      <td>0.067057</td>\n",
       "      <td>0.124995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.361000</td>\n",
       "      <td>19.892000</td>\n",
       "      <td>12.377000</td>\n",
       "      <td>0.736530</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.086699</td>\n",
       "      <td>22.361000</td>\n",
       "      <td>20.892000</td>\n",
       "      <td>13.378000</td>\n",
       "      <td>-0.133430</td>\n",
       "      <td>0.372330</td>\n",
       "      <td>-0.265200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>102.490000</td>\n",
       "      <td>97.884750</td>\n",
       "      <td>65.976750</td>\n",
       "      <td>1.197875</td>\n",
       "      <td>0.720082</td>\n",
       "      <td>0.330610</td>\n",
       "      <td>103.490000</td>\n",
       "      <td>98.884750</td>\n",
       "      <td>66.976750</td>\n",
       "      <td>0.865295</td>\n",
       "      <td>0.896250</td>\n",
       "      <td>0.809335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>137.160000</td>\n",
       "      <td>132.300000</td>\n",
       "      <td>93.642500</td>\n",
       "      <td>1.627500</td>\n",
       "      <td>0.915240</td>\n",
       "      <td>0.475155</td>\n",
       "      <td>138.160000</td>\n",
       "      <td>133.290000</td>\n",
       "      <td>94.642500</td>\n",
       "      <td>0.922910</td>\n",
       "      <td>0.932870</td>\n",
       "      <td>0.869140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>173.495000</td>\n",
       "      <td>156.610000</td>\n",
       "      <td>129.967500</td>\n",
       "      <td>2.944275</td>\n",
       "      <td>1.081225</td>\n",
       "      <td>0.708640</td>\n",
       "      <td>174.487500</td>\n",
       "      <td>157.610000</td>\n",
       "      <td>130.967500</td>\n",
       "      <td>0.950750</td>\n",
       "      <td>0.962770</td>\n",
       "      <td>0.904057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>254.350000</td>\n",
       "      <td>253.490000</td>\n",
       "      <td>252.390000</td>\n",
       "      <td>7.708500</td>\n",
       "      <td>2.395900</td>\n",
       "      <td>1.679100</td>\n",
       "      <td>254.300000</td>\n",
       "      <td>253.490000</td>\n",
       "      <td>252.340000</td>\n",
       "      <td>0.990840</td>\n",
       "      <td>0.995060</td>\n",
       "      <td>0.983550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               f1          f2          f3          f4          f5          f6  \\\n",
       "count  572.000000  572.000000  572.000000  572.000000  572.000000  572.000000   \n",
       "mean   136.630542  127.212857   98.524234    2.182164    0.932241    0.552174   \n",
       "std     48.221557   42.154986   44.261720    1.291193    0.304138    0.285861   \n",
       "min     21.361000   19.892000   12.377000    0.736530    0.272300    0.086699   \n",
       "25%    102.490000   97.884750   65.976750    1.197875    0.720082    0.330610   \n",
       "50%    137.160000  132.300000   93.642500    1.627500    0.915240    0.475155   \n",
       "75%    173.495000  156.610000  129.967500    2.944275    1.081225    0.708640   \n",
       "max    254.350000  253.490000  252.390000    7.708500    2.395900    1.679100   \n",
       "\n",
       "               f7          f8          f9         f10         f11         f12  \n",
       "count  572.000000  572.000000  572.000000  572.000000  572.000000  572.000000  \n",
       "mean   137.492710  128.149285   99.481678    0.893481    0.918244    0.835117  \n",
       "std     48.083568   42.084343   44.155740    0.097588    0.067057    0.124995  \n",
       "min     22.361000   20.892000   13.378000   -0.133430    0.372330   -0.265200  \n",
       "25%    103.490000   98.884750   66.976750    0.865295    0.896250    0.809335  \n",
       "50%    138.160000  133.290000   94.642500    0.922910    0.932870    0.869140  \n",
       "75%    174.487500  157.610000  130.967500    0.950750    0.962770    0.904057  \n",
       "max    254.300000  253.490000  252.340000    0.990840    0.995060    0.983550  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sony.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create trainig and testing data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Label Coloumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sony.loc[:,'label'] = pd.Series(0, index=sony.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102.640</td>\n",
       "      <td>112.140</td>\n",
       "      <td>55.575</td>\n",
       "      <td>4.1348</td>\n",
       "      <td>1.2005</td>\n",
       "      <td>0.29900</td>\n",
       "      <td>103.640</td>\n",
       "      <td>113.140</td>\n",
       "      <td>56.575</td>\n",
       "      <td>0.87457</td>\n",
       "      <td>0.77381</td>\n",
       "      <td>0.71383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.630</td>\n",
       "      <td>110.780</td>\n",
       "      <td>53.606</td>\n",
       "      <td>4.4764</td>\n",
       "      <td>1.1947</td>\n",
       "      <td>0.28115</td>\n",
       "      <td>102.630</td>\n",
       "      <td>111.780</td>\n",
       "      <td>54.617</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.79521</td>\n",
       "      <td>0.75612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.980</td>\n",
       "      <td>109.780</td>\n",
       "      <td>51.389</td>\n",
       "      <td>4.5646</td>\n",
       "      <td>1.1368</td>\n",
       "      <td>0.24906</td>\n",
       "      <td>103.980</td>\n",
       "      <td>110.780</td>\n",
       "      <td>52.389</td>\n",
       "      <td>0.84510</td>\n",
       "      <td>0.78767</td>\n",
       "      <td>0.76815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.370</td>\n",
       "      <td>110.890</td>\n",
       "      <td>51.504</td>\n",
       "      <td>4.6491</td>\n",
       "      <td>1.1973</td>\n",
       "      <td>0.25798</td>\n",
       "      <td>102.370</td>\n",
       "      <td>111.890</td>\n",
       "      <td>52.505</td>\n",
       "      <td>0.93628</td>\n",
       "      <td>0.89639</td>\n",
       "      <td>0.85926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.185</td>\n",
       "      <td>67.155</td>\n",
       "      <td>66.681</td>\n",
       "      <td>1.0122</td>\n",
       "      <td>1.0357</td>\n",
       "      <td>1.02410</td>\n",
       "      <td>67.185</td>\n",
       "      <td>68.155</td>\n",
       "      <td>67.681</td>\n",
       "      <td>0.85670</td>\n",
       "      <td>0.93231</td>\n",
       "      <td>0.86471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f1       f2      f3      f4      f5       f6       f7       f8  \\\n",
       "0  102.640  112.140  55.575  4.1348  1.2005  0.29900  103.640  113.140   \n",
       "1  101.630  110.780  53.606  4.4764  1.1947  0.28115  102.630  111.780   \n",
       "2  102.980  109.780  51.389  4.5646  1.1368  0.24906  103.980  110.780   \n",
       "3  101.370  110.890  51.504  4.6491  1.1973  0.25798  102.370  111.890   \n",
       "4   66.185   67.155  66.681  1.0122  1.0357  1.02410   67.185   68.155   \n",
       "\n",
       "       f9      f10      f11      f12  label  \n",
       "0  56.575  0.87457  0.77381  0.71383      0  \n",
       "1  54.617  0.90695  0.79521  0.75612      0  \n",
       "2  52.389  0.84510  0.78767  0.76815      0  \n",
       "3  52.505  0.93628  0.89639  0.85926      0  \n",
       "4  67.681  0.85670  0.93231  0.86471      0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sony.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.208</td>\n",
       "      <td>105.840</td>\n",
       "      <td>42.858</td>\n",
       "      <td>6.52910</td>\n",
       "      <td>1.8116</td>\n",
       "      <td>0.30781</td>\n",
       "      <td>80.208</td>\n",
       "      <td>106.840</td>\n",
       "      <td>43.859</td>\n",
       "      <td>0.85447</td>\n",
       "      <td>0.77848</td>\n",
       "      <td>0.80745</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.291</td>\n",
       "      <td>106.430</td>\n",
       "      <td>42.996</td>\n",
       "      <td>6.68600</td>\n",
       "      <td>1.7812</td>\n",
       "      <td>0.29750</td>\n",
       "      <td>81.291</td>\n",
       "      <td>107.430</td>\n",
       "      <td>44.225</td>\n",
       "      <td>0.89141</td>\n",
       "      <td>0.81405</td>\n",
       "      <td>0.82285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.349</td>\n",
       "      <td>96.970</td>\n",
       "      <td>35.675</td>\n",
       "      <td>7.42740</td>\n",
       "      <td>1.7487</td>\n",
       "      <td>0.23681</td>\n",
       "      <td>74.349</td>\n",
       "      <td>97.970</td>\n",
       "      <td>36.677</td>\n",
       "      <td>0.87635</td>\n",
       "      <td>0.83646</td>\n",
       "      <td>0.82346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.140</td>\n",
       "      <td>105.380</td>\n",
       "      <td>36.397</td>\n",
       "      <td>8.52830</td>\n",
       "      <td>1.8231</td>\n",
       "      <td>0.21769</td>\n",
       "      <td>79.140</td>\n",
       "      <td>106.380</td>\n",
       "      <td>37.525</td>\n",
       "      <td>0.93185</td>\n",
       "      <td>0.90865</td>\n",
       "      <td>0.88682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.171</td>\n",
       "      <td>43.542</td>\n",
       "      <td>51.721</td>\n",
       "      <td>0.70633</td>\n",
       "      <td>1.1850</td>\n",
       "      <td>1.68520</td>\n",
       "      <td>41.171</td>\n",
       "      <td>44.542</td>\n",
       "      <td>52.721</td>\n",
       "      <td>0.86081</td>\n",
       "      <td>0.88394</td>\n",
       "      <td>0.82186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1       f2      f3       f4      f5       f6      f7       f8      f9  \\\n",
       "0  79.208  105.840  42.858  6.52910  1.8116  0.30781  80.208  106.840  43.859   \n",
       "1  80.291  106.430  42.996  6.68600  1.7812  0.29750  81.291  107.430  44.225   \n",
       "2  73.349   96.970  35.675  7.42740  1.7487  0.23681  74.349   97.970  36.677   \n",
       "3  78.140  105.380  36.397  8.52830  1.8231  0.21769  79.140  106.380  37.525   \n",
       "4  40.171   43.542  51.721  0.70633  1.1850  1.68520  41.171   44.542  52.721   \n",
       "\n",
       "       f10      f11      f12  label  \n",
       "0  0.85447  0.77848  0.80745      1  \n",
       "1  0.89141  0.81405  0.82285      1  \n",
       "2  0.87635  0.83646  0.82346      1  \n",
       "3  0.93185  0.90865  0.88682      1  \n",
       "4  0.86081  0.88394  0.82186      1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nikon.loc[:,'label'] = pd.Series(1, index=nikon.index)\n",
    "nikon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Both data set & Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>145.340</td>\n",
       "      <td>148.890</td>\n",
       "      <td>147.650</td>\n",
       "      <td>1.01960</td>\n",
       "      <td>1.0482</td>\n",
       "      <td>1.02910</td>\n",
       "      <td>146.340</td>\n",
       "      <td>149.890</td>\n",
       "      <td>148.650</td>\n",
       "      <td>0.97593</td>\n",
       "      <td>0.98845</td>\n",
       "      <td>0.95466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>115.310</td>\n",
       "      <td>120.350</td>\n",
       "      <td>117.470</td>\n",
       "      <td>1.05390</td>\n",
       "      <td>1.0896</td>\n",
       "      <td>1.03720</td>\n",
       "      <td>116.310</td>\n",
       "      <td>121.350</td>\n",
       "      <td>118.470</td>\n",
       "      <td>0.96903</td>\n",
       "      <td>0.97760</td>\n",
       "      <td>0.96311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.208</td>\n",
       "      <td>105.840</td>\n",
       "      <td>42.858</td>\n",
       "      <td>6.52910</td>\n",
       "      <td>1.8116</td>\n",
       "      <td>0.30781</td>\n",
       "      <td>80.208</td>\n",
       "      <td>106.840</td>\n",
       "      <td>43.859</td>\n",
       "      <td>0.85447</td>\n",
       "      <td>0.77848</td>\n",
       "      <td>0.80745</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.291</td>\n",
       "      <td>106.430</td>\n",
       "      <td>42.996</td>\n",
       "      <td>6.68600</td>\n",
       "      <td>1.7812</td>\n",
       "      <td>0.29750</td>\n",
       "      <td>81.291</td>\n",
       "      <td>107.430</td>\n",
       "      <td>44.225</td>\n",
       "      <td>0.89141</td>\n",
       "      <td>0.81405</td>\n",
       "      <td>0.82285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.349</td>\n",
       "      <td>96.970</td>\n",
       "      <td>35.675</td>\n",
       "      <td>7.42740</td>\n",
       "      <td>1.7487</td>\n",
       "      <td>0.23681</td>\n",
       "      <td>74.349</td>\n",
       "      <td>97.970</td>\n",
       "      <td>36.677</td>\n",
       "      <td>0.87635</td>\n",
       "      <td>0.83646</td>\n",
       "      <td>0.82346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.140</td>\n",
       "      <td>105.380</td>\n",
       "      <td>36.397</td>\n",
       "      <td>8.52830</td>\n",
       "      <td>1.8231</td>\n",
       "      <td>0.21769</td>\n",
       "      <td>79.140</td>\n",
       "      <td>106.380</td>\n",
       "      <td>37.525</td>\n",
       "      <td>0.93185</td>\n",
       "      <td>0.90865</td>\n",
       "      <td>0.88682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.171</td>\n",
       "      <td>43.542</td>\n",
       "      <td>51.721</td>\n",
       "      <td>0.70633</td>\n",
       "      <td>1.1850</td>\n",
       "      <td>1.68520</td>\n",
       "      <td>41.171</td>\n",
       "      <td>44.542</td>\n",
       "      <td>52.721</td>\n",
       "      <td>0.86081</td>\n",
       "      <td>0.88394</td>\n",
       "      <td>0.82186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40.774</td>\n",
       "      <td>45.192</td>\n",
       "      <td>53.724</td>\n",
       "      <td>0.82203</td>\n",
       "      <td>1.2422</td>\n",
       "      <td>1.75300</td>\n",
       "      <td>41.775</td>\n",
       "      <td>46.192</td>\n",
       "      <td>54.949</td>\n",
       "      <td>0.88801</td>\n",
       "      <td>0.91445</td>\n",
       "      <td>0.85522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35.181</td>\n",
       "      <td>39.055</td>\n",
       "      <td>47.609</td>\n",
       "      <td>0.67296</td>\n",
       "      <td>1.2327</td>\n",
       "      <td>1.83180</td>\n",
       "      <td>36.181</td>\n",
       "      <td>40.055</td>\n",
       "      <td>48.609</td>\n",
       "      <td>0.89191</td>\n",
       "      <td>0.89635</td>\n",
       "      <td>0.84888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38.399</td>\n",
       "      <td>42.987</td>\n",
       "      <td>52.595</td>\n",
       "      <td>0.66774</td>\n",
       "      <td>1.2533</td>\n",
       "      <td>1.87700</td>\n",
       "      <td>39.399</td>\n",
       "      <td>43.987</td>\n",
       "      <td>53.595</td>\n",
       "      <td>0.88684</td>\n",
       "      <td>0.92748</td>\n",
       "      <td>0.87243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f1       f2       f3       f4      f5       f6       f7       f8  \\\n",
       "570  145.340  148.890  147.650  1.01960  1.0482  1.02910  146.340  149.890   \n",
       "571  115.310  120.350  117.470  1.05390  1.0896  1.03720  116.310  121.350   \n",
       "0     79.208  105.840   42.858  6.52910  1.8116  0.30781   80.208  106.840   \n",
       "1     80.291  106.430   42.996  6.68600  1.7812  0.29750   81.291  107.430   \n",
       "2     73.349   96.970   35.675  7.42740  1.7487  0.23681   74.349   97.970   \n",
       "3     78.140  105.380   36.397  8.52830  1.8231  0.21769   79.140  106.380   \n",
       "4     40.171   43.542   51.721  0.70633  1.1850  1.68520   41.171   44.542   \n",
       "5     40.774   45.192   53.724  0.82203  1.2422  1.75300   41.775   46.192   \n",
       "6     35.181   39.055   47.609  0.67296  1.2327  1.83180   36.181   40.055   \n",
       "7     38.399   42.987   52.595  0.66774  1.2533  1.87700   39.399   43.987   \n",
       "\n",
       "          f9      f10      f11      f12  label  \n",
       "570  148.650  0.97593  0.98845  0.95466      0  \n",
       "571  118.470  0.96903  0.97760  0.96311      0  \n",
       "0     43.859  0.85447  0.77848  0.80745      1  \n",
       "1     44.225  0.89141  0.81405  0.82285      1  \n",
       "2     36.677  0.87635  0.83646  0.82346      1  \n",
       "3     37.525  0.93185  0.90865  0.88682      1  \n",
       "4     52.721  0.86081  0.88394  0.82186      1  \n",
       "5     54.949  0.88801  0.91445  0.85522      1  \n",
       "6     48.609  0.89191  0.89635  0.84888      1  \n",
       "7     53.595  0.88684  0.92748  0.87243      1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([sony,nikon])\n",
    "data[570:580]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.63</td>\n",
       "      <td>110.78</td>\n",
       "      <td>53.606</td>\n",
       "      <td>4.4764</td>\n",
       "      <td>1.1947</td>\n",
       "      <td>0.28115</td>\n",
       "      <td>102.63</td>\n",
       "      <td>111.78</td>\n",
       "      <td>54.617</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.79521</td>\n",
       "      <td>0.75612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.98</td>\n",
       "      <td>109.78</td>\n",
       "      <td>51.389</td>\n",
       "      <td>4.5646</td>\n",
       "      <td>1.1368</td>\n",
       "      <td>0.24906</td>\n",
       "      <td>103.98</td>\n",
       "      <td>110.78</td>\n",
       "      <td>52.389</td>\n",
       "      <td>0.84510</td>\n",
       "      <td>0.78767</td>\n",
       "      <td>0.76815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1      f2      f3      f4      f5       f6      f7      f8      f9  \\\n",
       "1  101.63  110.78  53.606  4.4764  1.1947  0.28115  102.63  111.78  54.617   \n",
       "2  102.98  109.78  51.389  4.5646  1.1368  0.24906  103.98  110.78  52.389   \n",
       "\n",
       "       f10      f11      f12  \n",
       "1  0.90695  0.79521  0.75612  \n",
       "2  0.84510  0.78767  0.76815  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select all coulomn except label\n",
    "data[1:3].loc[:,data.columns != 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Norm_feature=normalize(data.loc[:,data.columns != 'label'], norm='l2', axis=1, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.45999290e-01,   4.87279427e-01,   2.41488801e-01, ...,\n",
       "          3.80024941e-03,   3.36241924e-03,   3.10178949e-03],\n",
       "       [  4.47797284e-01,   4.88113580e-01,   2.36196214e-01, ...,\n",
       "          3.99616006e-03,   3.50381657e-03,   3.33158007e-03],\n",
       "       [  4.55333414e-01,   4.85400099e-01,   2.27220128e-01, ...,\n",
       "          3.73666992e-03,   3.48273908e-03,   3.39643001e-03],\n",
       "       ..., \n",
       "       [  1.80790120e-03,   1.94379943e-03,   2.00351382e-03, ...,\n",
       "          3.08574876e-05,   2.83314981e-05,   2.81247037e-05],\n",
       "       [  3.87505428e-01,   3.99098978e-01,   4.26944795e-01, ...,\n",
       "          6.30237896e-03,   6.30663836e-03,   6.04608297e-03],\n",
       "       [  3.60030906e-01,   3.96406828e-01,   4.52133154e-01, ...,\n",
       "          6.28831395e-03,   6.39364252e-03,   6.12394185e-03]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Norm_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concatenate numpy array\n",
    "\n",
    "#training Set\n",
    "train_x=np.concatenate((Norm_feature[:540], Norm_feature[610:]), axis=0)\n",
    "train_y=np.concatenate((np.array(data[:540].loc[:,\"label\"]),np.array(data[610:].loc[:,\"label\"])),axis=0)\n",
    "\n",
    "#Testing Set\n",
    "test_x=Norm_feature[510:640]\n",
    "test_y=np.array(data[510:640].loc[:,\"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clsf = classifier\n",
    "clsf=SVC(kernel='rbf',gamma=70,C=2) #SVM Classier\n",
    "svm={} #store accuracy data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clsf = classifier\n",
    "clsf=SVC(kernel='rbf',gamma=90,C=2) #SVM Classier\n",
    "svm={} #store accuracy data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=90, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "clsf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  74.6965452848 %\n"
     ]
    }
   ],
   "source": [
    "#Now testing for trainig data\n",
    "#Now predict values for given classifier\n",
    "prediction = clsf.predict(train_x)\n",
    "svm[\"trainig_set\"]=accuracy_score(prediction,train_y)*100\n",
    "print 'Accuracy Check ',svm[\"trainig_set\"],'%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  67.6923076923 %\n"
     ]
    }
   ],
   "source": [
    "prediction = clsf.predict(test_x)\n",
    "svm[\"test_set\"]=accuracy_score(prediction,test_y)*100\n",
    "print 'Accuracy Check ',svm[\"test_set\"],'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_set': 67.692307692307693, 'trainig_set': 74.696545284780584}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=9,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision={}\n",
    "clf=DecisionTreeClassifier(max_depth=9,min_samples_split=4,criterion='entropy')\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "clf = clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  89.3557422969 %\n"
     ]
    }
   ],
   "source": [
    "#Now testing for trainig data\n",
    "#Now predict values for given classifier\n",
    "prediction = clf.predict(train_x)\n",
    "decision[\"trainig_set\"]=accuracy_score(prediction,train_y)*100\n",
    "print 'Accuracy Check ',decision[\"trainig_set\"],'%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  73.0769230769 %\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(test_x)\n",
    "decision[\"test_set\"]=accuracy_score(prediction,test_y)*100\n",
    "print 'Accuracy Check ',decision[\"test_set\"],'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_set': 79.230769230769226, 'trainig_set': 93.464052287581694}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Uses Backpropagation for trainig</li>\n",
    "<li></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', algorithm='l-bfgs', alpha=1e-05,\n",
       "       batch_size='auto', beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
       "       epsilon=1e-08, hidden_layer_sizes=(8, 9), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural=dict()\n",
    "clf = MLPClassifier(algorithm='l-bfgs',hidden_layer_sizes=(8,9), alpha=1e-5, activation='tanh')\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', algorithm='l-bfgs', alpha=1e-05,\n",
       "       batch_size='auto', beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
       "       epsilon=1e-08, hidden_layer_sizes=(8, 9), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainig Network\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  73.1092436975 %\n"
     ]
    }
   ],
   "source": [
    "#Now testing for trainig data\n",
    "#Now predict values for given classifier\n",
    "prediction = clf.predict(train_x)\n",
    "neural[\"trainig_set\"]=accuracy_score(prediction,train_y)*100\n",
    "print 'Accuracy Check ',neural[\"trainig_set\"],'%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  72.3076923077 %\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(test_x)\n",
    "neural[\"test_set\"]=accuracy_score(prediction,test_y)*100\n",
    "print 'Accuracy Check ',neural[\"test_set\"],'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_set': 72.307692307692307, 'trainig_set': 73.109243697478988}"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "plt.rcParams['figure.figsize'] = 16, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6oAAALYCAYAAAB14Q9gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEnSUPkfHLCA47a1a+YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc489b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%pylab inline\n",
    "classifier = [1,2,3]\n",
    "accuracy_test_data=[svm[\"test_set\"],decision[\"test_set\"],neural[\"test_set\"]]\n",
    "LABELS=[\"SVM\",\"Decision-Tree\",\"Neural-net\"]\n",
    "\n",
    "plt.bar(classifier,accuracy_test_data,align='center')\n",
    "plt.xticks(classifier, LABELS) #binding label with x axis data\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Analysis with 2 Class')\n",
    "plt.show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
