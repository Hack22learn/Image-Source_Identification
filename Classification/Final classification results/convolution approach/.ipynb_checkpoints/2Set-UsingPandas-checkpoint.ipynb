{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Identification using 2 Class of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.147</td>\n",
       "      <td>95.620</td>\n",
       "      <td>46.296</td>\n",
       "      <td>4.37480</td>\n",
       "      <td>1.24310</td>\n",
       "      <td>0.30249</td>\n",
       "      <td>87.147</td>\n",
       "      <td>96.620</td>\n",
       "      <td>47.296</td>\n",
       "      <td>0.89929</td>\n",
       "      <td>0.78737</td>\n",
       "      <td>0.75528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.063</td>\n",
       "      <td>94.421</td>\n",
       "      <td>45.271</td>\n",
       "      <td>4.54730</td>\n",
       "      <td>1.21540</td>\n",
       "      <td>0.28514</td>\n",
       "      <td>87.064</td>\n",
       "      <td>95.421</td>\n",
       "      <td>46.364</td>\n",
       "      <td>0.93156</td>\n",
       "      <td>0.80113</td>\n",
       "      <td>0.78903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.182</td>\n",
       "      <td>96.998</td>\n",
       "      <td>40.994</td>\n",
       "      <td>5.60200</td>\n",
       "      <td>1.18310</td>\n",
       "      <td>0.21126</td>\n",
       "      <td>90.182</td>\n",
       "      <td>97.998</td>\n",
       "      <td>41.994</td>\n",
       "      <td>0.88999</td>\n",
       "      <td>0.78921</td>\n",
       "      <td>0.82893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.092</td>\n",
       "      <td>98.772</td>\n",
       "      <td>42.287</td>\n",
       "      <td>5.46890</td>\n",
       "      <td>1.20230</td>\n",
       "      <td>0.22036</td>\n",
       "      <td>91.092</td>\n",
       "      <td>99.772</td>\n",
       "      <td>43.306</td>\n",
       "      <td>0.93447</td>\n",
       "      <td>0.82847</td>\n",
       "      <td>0.84858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.910</td>\n",
       "      <td>95.124</td>\n",
       "      <td>100.590</td>\n",
       "      <td>0.89057</td>\n",
       "      <td>0.98788</td>\n",
       "      <td>1.11290</td>\n",
       "      <td>96.910</td>\n",
       "      <td>96.124</td>\n",
       "      <td>101.590</td>\n",
       "      <td>0.94669</td>\n",
       "      <td>0.94299</td>\n",
       "      <td>0.92728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1      f2       f3       f4       f5       f6      f7      f8  \\\n",
       "0  86.147  95.620   46.296  4.37480  1.24310  0.30249  87.147  96.620   \n",
       "1  86.063  94.421   45.271  4.54730  1.21540  0.28514  87.064  95.421   \n",
       "2  89.182  96.998   40.994  5.60200  1.18310  0.21126  90.182  97.998   \n",
       "3  90.092  98.772   42.287  5.46890  1.20230  0.22036  91.092  99.772   \n",
       "4  95.910  95.124  100.590  0.89057  0.98788  1.11290  96.910  96.124   \n",
       "\n",
       "        f9      f10      f11      f12  \n",
       "0   47.296  0.89929  0.78737  0.75528  \n",
       "1   46.364  0.93156  0.80113  0.78903  \n",
       "2   41.994  0.88999  0.78921  0.82893  \n",
       "3   43.306  0.93447  0.82847  0.84858  \n",
       "4  101.590  0.94669  0.94299  0.92728  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sony=pd.read_csv(\"./data/sony_143_conv.csv\")\n",
    "sony.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.208</td>\n",
       "      <td>105.840</td>\n",
       "      <td>42.858</td>\n",
       "      <td>6.52910</td>\n",
       "      <td>1.8116</td>\n",
       "      <td>0.30781</td>\n",
       "      <td>80.208</td>\n",
       "      <td>106.840</td>\n",
       "      <td>43.859</td>\n",
       "      <td>0.85447</td>\n",
       "      <td>0.77848</td>\n",
       "      <td>0.80745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.291</td>\n",
       "      <td>106.430</td>\n",
       "      <td>42.996</td>\n",
       "      <td>6.68600</td>\n",
       "      <td>1.7812</td>\n",
       "      <td>0.29750</td>\n",
       "      <td>81.291</td>\n",
       "      <td>107.430</td>\n",
       "      <td>44.225</td>\n",
       "      <td>0.89141</td>\n",
       "      <td>0.81405</td>\n",
       "      <td>0.82285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.349</td>\n",
       "      <td>96.970</td>\n",
       "      <td>35.675</td>\n",
       "      <td>7.42740</td>\n",
       "      <td>1.7487</td>\n",
       "      <td>0.23681</td>\n",
       "      <td>74.349</td>\n",
       "      <td>97.970</td>\n",
       "      <td>36.677</td>\n",
       "      <td>0.87635</td>\n",
       "      <td>0.83646</td>\n",
       "      <td>0.82346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.140</td>\n",
       "      <td>105.380</td>\n",
       "      <td>36.397</td>\n",
       "      <td>8.52830</td>\n",
       "      <td>1.8231</td>\n",
       "      <td>0.21769</td>\n",
       "      <td>79.140</td>\n",
       "      <td>106.380</td>\n",
       "      <td>37.525</td>\n",
       "      <td>0.93185</td>\n",
       "      <td>0.90865</td>\n",
       "      <td>0.88682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.171</td>\n",
       "      <td>43.542</td>\n",
       "      <td>51.721</td>\n",
       "      <td>0.70633</td>\n",
       "      <td>1.1850</td>\n",
       "      <td>1.68520</td>\n",
       "      <td>41.171</td>\n",
       "      <td>44.542</td>\n",
       "      <td>52.721</td>\n",
       "      <td>0.86081</td>\n",
       "      <td>0.88394</td>\n",
       "      <td>0.82186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1       f2      f3       f4      f5       f6      f7       f8      f9  \\\n",
       "0  79.208  105.840  42.858  6.52910  1.8116  0.30781  80.208  106.840  43.859   \n",
       "1  80.291  106.430  42.996  6.68600  1.7812  0.29750  81.291  107.430  44.225   \n",
       "2  73.349   96.970  35.675  7.42740  1.7487  0.23681  74.349   97.970  36.677   \n",
       "3  78.140  105.380  36.397  8.52830  1.8231  0.21769  79.140  106.380  37.525   \n",
       "4  40.171   43.542  51.721  0.70633  1.1850  1.68520  41.171   44.542  52.721   \n",
       "\n",
       "       f10      f11      f12  \n",
       "0  0.85447  0.77848  0.80745  \n",
       "1  0.89141  0.81405  0.82285  \n",
       "2  0.87635  0.83646  0.82346  \n",
       "3  0.93185  0.90865  0.88682  \n",
       "4  0.86081  0.88394  0.82186  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nikon=pd.read_csv(\"./data/nikkon_143_conv.csv\")\n",
    "nikon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>108.924137</td>\n",
       "      <td>99.437256</td>\n",
       "      <td>72.444076</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.962328</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>109.898660</td>\n",
       "      <td>100.427830</td>\n",
       "      <td>73.998986</td>\n",
       "      <td>0.921288</td>\n",
       "      <td>0.898338</td>\n",
       "      <td>0.863663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41.023914</td>\n",
       "      <td>34.661177</td>\n",
       "      <td>40.270545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.487846</td>\n",
       "      <td>0.403528</td>\n",
       "      <td>41.003573</td>\n",
       "      <td>34.653427</td>\n",
       "      <td>39.788428</td>\n",
       "      <td>0.106261</td>\n",
       "      <td>0.132954</td>\n",
       "      <td>0.159995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.210000</td>\n",
       "      <td>10.736000</td>\n",
       "      <td>0.429930</td>\n",
       "      <td>0.616350</td>\n",
       "      <td>0.130310</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>21.346000</td>\n",
       "      <td>11.736000</td>\n",
       "      <td>2.679500</td>\n",
       "      <td>-0.461420</td>\n",
       "      <td>0.005230</td>\n",
       "      <td>-0.352930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>78.142750</td>\n",
       "      <td>73.890250</td>\n",
       "      <td>41.654250</td>\n",
       "      <td>1.143550</td>\n",
       "      <td>0.656170</td>\n",
       "      <td>0.186515</td>\n",
       "      <td>79.116000</td>\n",
       "      <td>74.890250</td>\n",
       "      <td>43.203500</td>\n",
       "      <td>0.904648</td>\n",
       "      <td>0.876320</td>\n",
       "      <td>0.833540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>107.525000</td>\n",
       "      <td>101.130000</td>\n",
       "      <td>67.979500</td>\n",
       "      <td>1.788900</td>\n",
       "      <td>0.881715</td>\n",
       "      <td>0.440700</td>\n",
       "      <td>108.520000</td>\n",
       "      <td>102.130000</td>\n",
       "      <td>69.137000</td>\n",
       "      <td>0.949065</td>\n",
       "      <td>0.940370</td>\n",
       "      <td>0.910810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>140.582500</td>\n",
       "      <td>125.327500</td>\n",
       "      <td>102.300000</td>\n",
       "      <td>6.430175</td>\n",
       "      <td>1.095675</td>\n",
       "      <td>0.746632</td>\n",
       "      <td>141.450000</td>\n",
       "      <td>126.327500</td>\n",
       "      <td>103.300000</td>\n",
       "      <td>0.975998</td>\n",
       "      <td>0.976490</td>\n",
       "      <td>0.952340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>220.040000</td>\n",
       "      <td>217.320000</td>\n",
       "      <td>211.750000</td>\n",
       "      <td>inf</td>\n",
       "      <td>3.638000</td>\n",
       "      <td>3.393600</td>\n",
       "      <td>221.040000</td>\n",
       "      <td>218.320000</td>\n",
       "      <td>212.750000</td>\n",
       "      <td>0.998890</td>\n",
       "      <td>0.998640</td>\n",
       "      <td>0.997860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               f1          f2          f3          f4          f5          f6  \\\n",
       "count  570.000000  570.000000  570.000000  570.000000  570.000000  570.000000   \n",
       "mean   108.924137   99.437256   72.444076         inf    0.962328    0.506735   \n",
       "std     41.023914   34.661177   40.270545         NaN    0.487846    0.403528   \n",
       "min     20.210000   10.736000    0.429930    0.616350    0.130310    0.000190   \n",
       "25%     78.142750   73.890250   41.654250    1.143550    0.656170    0.186515   \n",
       "50%    107.525000  101.130000   67.979500    1.788900    0.881715    0.440700   \n",
       "75%    140.582500  125.327500  102.300000    6.430175    1.095675    0.746632   \n",
       "max    220.040000  217.320000  211.750000         inf    3.638000    3.393600   \n",
       "\n",
       "               f7          f8          f9         f10         f11         f12  \n",
       "count  570.000000  570.000000  570.000000  570.000000  569.000000  569.000000  \n",
       "mean   109.898660  100.427830   73.998986    0.921288    0.898338    0.863663  \n",
       "std     41.003573   34.653427   39.788428    0.106261    0.132954    0.159995  \n",
       "min     21.346000   11.736000    2.679500   -0.461420    0.005230   -0.352930  \n",
       "25%     79.116000   74.890250   43.203500    0.904648    0.876320    0.833540  \n",
       "50%    108.520000  102.130000   69.137000    0.949065    0.940370    0.910810  \n",
       "75%    141.450000  126.327500  103.300000    0.975998    0.976490    0.952340  \n",
       "max    221.040000  218.320000  212.750000    0.998890    0.998640    0.997860  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nikon.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>572.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>127.441154</td>\n",
       "      <td>112.369545</td>\n",
       "      <td>83.800322</td>\n",
       "      <td>3.042400</td>\n",
       "      <td>0.826711</td>\n",
       "      <td>0.459668</td>\n",
       "      <td>128.415000</td>\n",
       "      <td>113.368755</td>\n",
       "      <td>84.843322</td>\n",
       "      <td>0.890478</td>\n",
       "      <td>0.889341</td>\n",
       "      <td>0.834397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43.589198</td>\n",
       "      <td>38.756441</td>\n",
       "      <td>40.929062</td>\n",
       "      <td>3.310602</td>\n",
       "      <td>0.281211</td>\n",
       "      <td>0.282342</td>\n",
       "      <td>43.582902</td>\n",
       "      <td>38.754296</td>\n",
       "      <td>40.866013</td>\n",
       "      <td>0.107436</td>\n",
       "      <td>0.114403</td>\n",
       "      <td>0.160840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.526000</td>\n",
       "      <td>22.062000</td>\n",
       "      <td>10.333000</td>\n",
       "      <td>0.774680</td>\n",
       "      <td>0.158190</td>\n",
       "      <td>0.041275</td>\n",
       "      <td>31.526000</td>\n",
       "      <td>23.062000</td>\n",
       "      <td>11.472000</td>\n",
       "      <td>0.091059</td>\n",
       "      <td>-0.034645</td>\n",
       "      <td>-0.199180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>96.029250</td>\n",
       "      <td>85.622000</td>\n",
       "      <td>52.716750</td>\n",
       "      <td>1.235700</td>\n",
       "      <td>0.619528</td>\n",
       "      <td>0.250352</td>\n",
       "      <td>97.029250</td>\n",
       "      <td>86.622000</td>\n",
       "      <td>53.821250</td>\n",
       "      <td>0.855715</td>\n",
       "      <td>0.856520</td>\n",
       "      <td>0.801460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>123.635000</td>\n",
       "      <td>110.405000</td>\n",
       "      <td>79.778000</td>\n",
       "      <td>1.800850</td>\n",
       "      <td>0.811185</td>\n",
       "      <td>0.401345</td>\n",
       "      <td>124.635000</td>\n",
       "      <td>111.405000</td>\n",
       "      <td>80.992000</td>\n",
       "      <td>0.921765</td>\n",
       "      <td>0.916075</td>\n",
       "      <td>0.878230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>159.675000</td>\n",
       "      <td>138.187500</td>\n",
       "      <td>111.075000</td>\n",
       "      <td>3.599975</td>\n",
       "      <td>0.961790</td>\n",
       "      <td>0.645333</td>\n",
       "      <td>160.675000</td>\n",
       "      <td>139.187500</td>\n",
       "      <td>112.082500</td>\n",
       "      <td>0.962292</td>\n",
       "      <td>0.959642</td>\n",
       "      <td>0.927722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.360000</td>\n",
       "      <td>236.580000</td>\n",
       "      <td>230.440000</td>\n",
       "      <td>27.239000</td>\n",
       "      <td>2.185100</td>\n",
       "      <td>2.268700</td>\n",
       "      <td>245.360000</td>\n",
       "      <td>237.570000</td>\n",
       "      <td>231.440000</td>\n",
       "      <td>0.994660</td>\n",
       "      <td>0.995520</td>\n",
       "      <td>0.991670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               f1          f2          f3          f4          f5          f6  \\\n",
       "count  572.000000  572.000000  572.000000  572.000000  572.000000  572.000000   \n",
       "mean   127.441154  112.369545   83.800322    3.042400    0.826711    0.459668   \n",
       "std     43.589198   38.756441   40.929062    3.310602    0.281211    0.282342   \n",
       "min     30.526000   22.062000   10.333000    0.774680    0.158190    0.041275   \n",
       "25%     96.029250   85.622000   52.716750    1.235700    0.619528    0.250352   \n",
       "50%    123.635000  110.405000   79.778000    1.800850    0.811185    0.401345   \n",
       "75%    159.675000  138.187500  111.075000    3.599975    0.961790    0.645333   \n",
       "max    244.360000  236.580000  230.440000   27.239000    2.185100    2.268700   \n",
       "\n",
       "               f7          f8          f9         f10         f11         f12  \n",
       "count  572.000000  572.000000  572.000000  572.000000  572.000000  572.000000  \n",
       "mean   128.415000  113.368755   84.843322    0.890478    0.889341    0.834397  \n",
       "std     43.582902   38.754296   40.866013    0.107436    0.114403    0.160840  \n",
       "min     31.526000   23.062000   11.472000    0.091059   -0.034645   -0.199180  \n",
       "25%     97.029250   86.622000   53.821250    0.855715    0.856520    0.801460  \n",
       "50%    124.635000  111.405000   80.992000    0.921765    0.916075    0.878230  \n",
       "75%    160.675000  139.187500  112.082500    0.962292    0.959642    0.927722  \n",
       "max    245.360000  237.570000  231.440000    0.994660    0.995520    0.991670  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sony.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create trainig and testing data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Label Coloumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sony.loc[:,'label'] = pd.Series(0, index=sony.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.147</td>\n",
       "      <td>95.620</td>\n",
       "      <td>46.296</td>\n",
       "      <td>4.37480</td>\n",
       "      <td>1.24310</td>\n",
       "      <td>0.30249</td>\n",
       "      <td>87.147</td>\n",
       "      <td>96.620</td>\n",
       "      <td>47.296</td>\n",
       "      <td>0.89929</td>\n",
       "      <td>0.78737</td>\n",
       "      <td>0.75528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.063</td>\n",
       "      <td>94.421</td>\n",
       "      <td>45.271</td>\n",
       "      <td>4.54730</td>\n",
       "      <td>1.21540</td>\n",
       "      <td>0.28514</td>\n",
       "      <td>87.064</td>\n",
       "      <td>95.421</td>\n",
       "      <td>46.364</td>\n",
       "      <td>0.93156</td>\n",
       "      <td>0.80113</td>\n",
       "      <td>0.78903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.182</td>\n",
       "      <td>96.998</td>\n",
       "      <td>40.994</td>\n",
       "      <td>5.60200</td>\n",
       "      <td>1.18310</td>\n",
       "      <td>0.21126</td>\n",
       "      <td>90.182</td>\n",
       "      <td>97.998</td>\n",
       "      <td>41.994</td>\n",
       "      <td>0.88999</td>\n",
       "      <td>0.78921</td>\n",
       "      <td>0.82893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.092</td>\n",
       "      <td>98.772</td>\n",
       "      <td>42.287</td>\n",
       "      <td>5.46890</td>\n",
       "      <td>1.20230</td>\n",
       "      <td>0.22036</td>\n",
       "      <td>91.092</td>\n",
       "      <td>99.772</td>\n",
       "      <td>43.306</td>\n",
       "      <td>0.93447</td>\n",
       "      <td>0.82847</td>\n",
       "      <td>0.84858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.910</td>\n",
       "      <td>95.124</td>\n",
       "      <td>100.590</td>\n",
       "      <td>0.89057</td>\n",
       "      <td>0.98788</td>\n",
       "      <td>1.11290</td>\n",
       "      <td>96.910</td>\n",
       "      <td>96.124</td>\n",
       "      <td>101.590</td>\n",
       "      <td>0.94669</td>\n",
       "      <td>0.94299</td>\n",
       "      <td>0.92728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1      f2       f3       f4       f5       f6      f7      f8  \\\n",
       "0  86.147  95.620   46.296  4.37480  1.24310  0.30249  87.147  96.620   \n",
       "1  86.063  94.421   45.271  4.54730  1.21540  0.28514  87.064  95.421   \n",
       "2  89.182  96.998   40.994  5.60200  1.18310  0.21126  90.182  97.998   \n",
       "3  90.092  98.772   42.287  5.46890  1.20230  0.22036  91.092  99.772   \n",
       "4  95.910  95.124  100.590  0.89057  0.98788  1.11290  96.910  96.124   \n",
       "\n",
       "        f9      f10      f11      f12  label  \n",
       "0   47.296  0.89929  0.78737  0.75528      0  \n",
       "1   46.364  0.93156  0.80113  0.78903      0  \n",
       "2   41.994  0.88999  0.78921  0.82893      0  \n",
       "3   43.306  0.93447  0.82847  0.84858      0  \n",
       "4  101.590  0.94669  0.94299  0.92728      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sony.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.208</td>\n",
       "      <td>105.840</td>\n",
       "      <td>42.858</td>\n",
       "      <td>6.52910</td>\n",
       "      <td>1.8116</td>\n",
       "      <td>0.30781</td>\n",
       "      <td>80.208</td>\n",
       "      <td>106.840</td>\n",
       "      <td>43.859</td>\n",
       "      <td>0.85447</td>\n",
       "      <td>0.77848</td>\n",
       "      <td>0.80745</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.291</td>\n",
       "      <td>106.430</td>\n",
       "      <td>42.996</td>\n",
       "      <td>6.68600</td>\n",
       "      <td>1.7812</td>\n",
       "      <td>0.29750</td>\n",
       "      <td>81.291</td>\n",
       "      <td>107.430</td>\n",
       "      <td>44.225</td>\n",
       "      <td>0.89141</td>\n",
       "      <td>0.81405</td>\n",
       "      <td>0.82285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.349</td>\n",
       "      <td>96.970</td>\n",
       "      <td>35.675</td>\n",
       "      <td>7.42740</td>\n",
       "      <td>1.7487</td>\n",
       "      <td>0.23681</td>\n",
       "      <td>74.349</td>\n",
       "      <td>97.970</td>\n",
       "      <td>36.677</td>\n",
       "      <td>0.87635</td>\n",
       "      <td>0.83646</td>\n",
       "      <td>0.82346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.140</td>\n",
       "      <td>105.380</td>\n",
       "      <td>36.397</td>\n",
       "      <td>8.52830</td>\n",
       "      <td>1.8231</td>\n",
       "      <td>0.21769</td>\n",
       "      <td>79.140</td>\n",
       "      <td>106.380</td>\n",
       "      <td>37.525</td>\n",
       "      <td>0.93185</td>\n",
       "      <td>0.90865</td>\n",
       "      <td>0.88682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.171</td>\n",
       "      <td>43.542</td>\n",
       "      <td>51.721</td>\n",
       "      <td>0.70633</td>\n",
       "      <td>1.1850</td>\n",
       "      <td>1.68520</td>\n",
       "      <td>41.171</td>\n",
       "      <td>44.542</td>\n",
       "      <td>52.721</td>\n",
       "      <td>0.86081</td>\n",
       "      <td>0.88394</td>\n",
       "      <td>0.82186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1       f2      f3       f4      f5       f6      f7       f8      f9  \\\n",
       "0  79.208  105.840  42.858  6.52910  1.8116  0.30781  80.208  106.840  43.859   \n",
       "1  80.291  106.430  42.996  6.68600  1.7812  0.29750  81.291  107.430  44.225   \n",
       "2  73.349   96.970  35.675  7.42740  1.7487  0.23681  74.349   97.970  36.677   \n",
       "3  78.140  105.380  36.397  8.52830  1.8231  0.21769  79.140  106.380  37.525   \n",
       "4  40.171   43.542  51.721  0.70633  1.1850  1.68520  41.171   44.542  52.721   \n",
       "\n",
       "       f10      f11      f12  label  \n",
       "0  0.85447  0.77848  0.80745      1  \n",
       "1  0.89141  0.81405  0.82285      1  \n",
       "2  0.87635  0.83646  0.82346      1  \n",
       "3  0.93185  0.90865  0.88682      1  \n",
       "4  0.86081  0.88394  0.82186      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nikon.loc[:,'label'] = pd.Series(1, index=nikon.index)\n",
    "nikon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Both data set & Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>161.71</td>\n",
       "      <td>131.89</td>\n",
       "      <td>110.90</td>\n",
       "      <td>1.5116</td>\n",
       "      <td>0.65243</td>\n",
       "      <td>0.45937</td>\n",
       "      <td>162.71</td>\n",
       "      <td>132.89</td>\n",
       "      <td>111.91</td>\n",
       "      <td>0.97643</td>\n",
       "      <td>0.98182</td>\n",
       "      <td>0.96086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>173.15</td>\n",
       "      <td>146.85</td>\n",
       "      <td>128.03</td>\n",
       "      <td>1.3545</td>\n",
       "      <td>0.70916</td>\n",
       "      <td>0.53867</td>\n",
       "      <td>174.15</td>\n",
       "      <td>147.85</td>\n",
       "      <td>129.03</td>\n",
       "      <td>0.98283</td>\n",
       "      <td>0.98849</td>\n",
       "      <td>0.97558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>185.18</td>\n",
       "      <td>164.29</td>\n",
       "      <td>144.42</td>\n",
       "      <td>1.2942</td>\n",
       "      <td>0.78713</td>\n",
       "      <td>0.60824</td>\n",
       "      <td>186.18</td>\n",
       "      <td>165.29</td>\n",
       "      <td>145.42</td>\n",
       "      <td>0.98429</td>\n",
       "      <td>0.98715</td>\n",
       "      <td>0.97766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>186.89</td>\n",
       "      <td>166.24</td>\n",
       "      <td>147.29</td>\n",
       "      <td>1.2739</td>\n",
       "      <td>0.79124</td>\n",
       "      <td>0.62114</td>\n",
       "      <td>187.89</td>\n",
       "      <td>167.24</td>\n",
       "      <td>148.29</td>\n",
       "      <td>0.97915</td>\n",
       "      <td>0.98478</td>\n",
       "      <td>0.97142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>216.40</td>\n",
       "      <td>200.16</td>\n",
       "      <td>164.23</td>\n",
       "      <td>1.5701</td>\n",
       "      <td>0.85561</td>\n",
       "      <td>0.57962</td>\n",
       "      <td>217.40</td>\n",
       "      <td>201.16</td>\n",
       "      <td>165.23</td>\n",
       "      <td>0.91724</td>\n",
       "      <td>0.92193</td>\n",
       "      <td>0.91064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>221.21</td>\n",
       "      <td>203.96</td>\n",
       "      <td>157.44</td>\n",
       "      <td>1.7406</td>\n",
       "      <td>0.85361</td>\n",
       "      <td>0.50878</td>\n",
       "      <td>222.21</td>\n",
       "      <td>204.96</td>\n",
       "      <td>158.44</td>\n",
       "      <td>0.84064</td>\n",
       "      <td>0.85479</td>\n",
       "      <td>0.75917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>207.92</td>\n",
       "      <td>203.80</td>\n",
       "      <td>135.33</td>\n",
       "      <td>2.2685</td>\n",
       "      <td>0.96083</td>\n",
       "      <td>0.42364</td>\n",
       "      <td>208.92</td>\n",
       "      <td>204.80</td>\n",
       "      <td>136.33</td>\n",
       "      <td>0.79363</td>\n",
       "      <td>0.79438</td>\n",
       "      <td>0.91158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>208.87</td>\n",
       "      <td>205.90</td>\n",
       "      <td>136.05</td>\n",
       "      <td>2.2908</td>\n",
       "      <td>0.97177</td>\n",
       "      <td>0.42431</td>\n",
       "      <td>209.87</td>\n",
       "      <td>206.90</td>\n",
       "      <td>137.05</td>\n",
       "      <td>0.79927</td>\n",
       "      <td>0.78778</td>\n",
       "      <td>0.92994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1      f2      f3      f4       f5       f6      f7      f8      f9  \\\n",
       "140  161.71  131.89  110.90  1.5116  0.65243  0.45937  162.71  132.89  111.91   \n",
       "141  173.15  146.85  128.03  1.3545  0.70916  0.53867  174.15  147.85  129.03   \n",
       "142  185.18  164.29  144.42  1.2942  0.78713  0.60824  186.18  165.29  145.42   \n",
       "143  186.89  166.24  147.29  1.2739  0.79124  0.62114  187.89  167.24  148.29   \n",
       "144  216.40  200.16  164.23  1.5701  0.85561  0.57962  217.40  201.16  165.23   \n",
       "145  221.21  203.96  157.44  1.7406  0.85361  0.50878  222.21  204.96  158.44   \n",
       "146  207.92  203.80  135.33  2.2685  0.96083  0.42364  208.92  204.80  136.33   \n",
       "147  208.87  205.90  136.05  2.2908  0.97177  0.42431  209.87  206.90  137.05   \n",
       "\n",
       "         f10      f11      f12  label  \n",
       "140  0.97643  0.98182  0.96086      0  \n",
       "141  0.98283  0.98849  0.97558      0  \n",
       "142  0.98429  0.98715  0.97766      0  \n",
       "143  0.97915  0.98478  0.97142      0  \n",
       "144  0.91724  0.92193  0.91064      0  \n",
       "145  0.84064  0.85479  0.75917      0  \n",
       "146  0.79363  0.79438  0.91158      0  \n",
       "147  0.79927  0.78778  0.92994      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([sony,nikon])\n",
    "data[140:148]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>Var12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.036287</td>\n",
       "      <td>126.017584</td>\n",
       "      <td>126.640565</td>\n",
       "      <td>0.995081</td>\n",
       "      <td>1.007848</td>\n",
       "      <td>1.012831</td>\n",
       "      <td>-1097190</td>\n",
       "      <td>-1068678</td>\n",
       "      <td>-753861</td>\n",
       "      <td>0.992517</td>\n",
       "      <td>0.984211</td>\n",
       "      <td>0.974200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109.158400</td>\n",
       "      <td>106.371291</td>\n",
       "      <td>104.290264</td>\n",
       "      <td>1.019954</td>\n",
       "      <td>0.974467</td>\n",
       "      <td>0.955403</td>\n",
       "      <td>157</td>\n",
       "      <td>641</td>\n",
       "      <td>-3146</td>\n",
       "      <td>0.944636</td>\n",
       "      <td>0.975875</td>\n",
       "      <td>0.884661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Var1        Var2        Var3      Var4      Var5      Var6     Var7  \\\n",
       "1  125.036287  126.017584  126.640565  0.995081  1.007848  1.012831 -1097190   \n",
       "2  109.158400  106.371291  104.290264  1.019954  0.974467  0.955403      157   \n",
       "\n",
       "      Var8    Var9     Var10     Var11     Var12  \n",
       "1 -1068678 -753861  0.992517  0.984211  0.974200  \n",
       "2      641   -3146  0.944636  0.975875  0.884661  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select all coulomn except label\n",
    "data[1:3].loc[:,data.columns != 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Norm_feature=normalize(data.loc[:,data.columns != 'label'], norm='l2', axis=1, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.52823583e-03,   3.62586141e-03,   3.26940692e-03, ...,\n",
       "          3.01275055e-05,   3.00148129e-05,   2.96453648e-05],\n",
       "       [  7.32446682e-05,   7.38194998e-05,   7.41844344e-05, ...,\n",
       "          5.81403910e-07,   5.76538359e-07,   5.70674174e-07],\n",
       "       [  3.39024810e-02,   3.30368593e-02,   3.23905326e-02, ...,\n",
       "          2.93385469e-04,   3.03087691e-04,   2.74758635e-04],\n",
       "       ..., \n",
       "       [  4.36099705e-04,   4.24614258e-04,   4.01317458e-04, ...,\n",
       "          3.55435779e-06,   3.55703070e-06,   3.42947537e-06],\n",
       "       [  4.87460414e-04,   5.01475208e-04,   4.82155777e-04, ...,\n",
       "          4.23647775e-06,   4.26887807e-06,   4.04420111e-06],\n",
       "       [  1.74080612e-04,   1.81601297e-04,   1.78560484e-04, ...,\n",
       "          1.70667166e-06,   1.69572507e-06,   1.63680092e-06]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Norm_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concatenate numpy array\n",
    "\n",
    "#training Set\n",
    "train_x=np.concatenate((Norm_feature[15:144], Norm_feature[160:]), axis=0)\n",
    "train_y=np.concatenate((np.array(data[15:144].loc[:,\"label\"]),np.array(data[160:].loc[:,\"label\"])),axis=0)\n",
    "\n",
    "#Testing Set\n",
    "test_x=np.concatenate((Norm_feature[0:15], Norm_feature[144:160]), axis=0)\n",
    "test_y=np.concatenate((np.array(data[0:15].loc[:,\"label\"]),np.array(data[144:160].loc[:,\"label\"])),axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clsf = classifier\n",
    "clsf=SVC(kernel='rbf',gamma=10,C=1) #SVM Classier\n",
    "svm={} #store accuracy data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=10, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "clsf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  82.7450980392 %\n"
     ]
    }
   ],
   "source": [
    "#Now testing for trainig data\n",
    "#Now predict values for given classifier\n",
    "prediction = clsf.predict(train_x)\n",
    "svm[\"trainig_set\"]=accuracy_score(prediction,train_y)*100\n",
    "print 'Accuracy Check ',svm[\"trainig_set\"],'%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  74.1935483871 %\n"
     ]
    }
   ],
   "source": [
    "prediction = clsf.predict(test_x)\n",
    "svm[\"test_set\"]=accuracy_score(prediction,test_y)*100\n",
    "print 'Accuracy Check ',svm[\"test_set\"],'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_set': 74.193548387096769, 'trainig_set': 82.745098039215677}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d492f8d22a50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "decision={}\n",
    "clf=DecisionTreeClassifier(max_depth=10,min_samples_split=4)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "clf = clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  98.0392156863 %\n"
     ]
    }
   ],
   "source": [
    "#Now testing for trainig data\n",
    "#Now predict values for given classifier\n",
    "prediction = clf.predict(train_x)\n",
    "decision[\"trainig_set\"]=accuracy_score(prediction,train_y)*100\n",
    "print 'Accuracy Check ',decision[\"trainig_set\"],'%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  80.6451612903 %\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(test_x)\n",
    "decision[\"test_set\"]=accuracy_score(prediction,test_y)*100\n",
    "print 'Accuracy Check ',decision[\"test_set\"],'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_set': 80.645161290322577, 'trainig_set': 98.039215686274503}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-mean Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=2, n_init=1,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean={}\n",
    "clust=KMeans(n_clusters=2,n_init=1)\n",
    "clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=2, n_init=1,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clust.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuraccy(pred,expected):\n",
    "    #calculate positive and negative prediction\n",
    "    pos=0\n",
    "    for i in pred:\n",
    "        if i==expected:\n",
    "            pos+=1\n",
    "    return pos\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  67.8431372549 %\n"
     ]
    }
   ],
   "source": [
    "#defining class then cheking class\n",
    "expected=clust.predict(train_x[0].reshape(1,12))[0]\n",
    "pos=accuraccy(clust.predict(train_x[:128]),expected)\n",
    "\n",
    "expected2=clust.predict(train_x[-1].reshape(1,12))[0]\n",
    "if expected2==expected:\n",
    "    expected2=clust.predict(train_x[-5].reshape(1,12))[0]\n",
    "    if expected2==expected:\n",
    "        print \"Error in class , fix it mannually\"\n",
    "else:\n",
    "    pos+=accuraccy(clust.predict(train_x[128:]),expected2)\n",
    "kmean[\"trainig_set\"]=(pos/float(len(train_y)))*100\n",
    "print 'Accuracy Check ',kmean[\"trainig_set\"],'%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  67.7419354839 %\n"
     ]
    }
   ],
   "source": [
    "#defining class then cheking class\n",
    "expected=clust.predict(test_x[0].reshape(1,12))[0]\n",
    "pos=accuraccy(clust.predict(test_x[:15]),expected)\n",
    "\n",
    "expected2=clust.predict(test_x[-1].reshape(1,12))[0]\n",
    "if expected2==expected:\n",
    "    expected2=clust.predict(train_x[-5].reshape(1,12))[0]\n",
    "    if expected2==expected:\n",
    "        print \"Error in class , fix it mannually\"\n",
    "else:\n",
    "    pos+=accuraccy(clust.predict(train_x[144:160]),expected2)\n",
    "kmean[\"test_set\"]=(pos/float(len(test_y)))*100\n",
    "print 'Accuracy Check ',kmean[\"test_set\"],'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_set': 67.74193548387096, 'trainig_set': 67.84313725490196}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Uses Backpropagation for trainig</li>\n",
    "<li></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', algorithm='l-bfgs', alpha=1e-05,\n",
       "       batch_size=200, beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
       "       epsilon=1e-08, hidden_layer_sizes=(50,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural=dict()\n",
    "clf = MLPClassifier(algorithm='l-bfgs',hidden_layer_sizes=(50,), alpha=1e-5, random_state=1)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', algorithm='l-bfgs', alpha=1e-05,\n",
       "       batch_size=200, beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
       "       epsilon=1e-08, hidden_layer_sizes=(50,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainig Network\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  88.6274509804 %\n"
     ]
    }
   ],
   "source": [
    "#Now testing for trainig data\n",
    "#Now predict values for given classifier\n",
    "prediction = clf.predict(train_x)\n",
    "neural[\"trainig_set\"]=accuracy_score(prediction,train_y)*100\n",
    "print 'Accuracy Check ',neural[\"trainig_set\"],'%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Check  80.6451612903 %\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(test_x)\n",
    "neural[\"test_set\"]=accuracy_score(prediction,test_y)*100\n",
    "print 'Accuracy Check ',neural[\"test_set\"],'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_set': 80.645161290322577, 'trainig_set': 88.627450980392155}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "plt.rcParams['figure.figsize'] = 16, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6oAAALYCAYAAAB14Q9gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzNrKO6ompmZmZmZWUP5P8YONvlhOkc7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9aa6268c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%pylab inline\n",
    "classifier = [1,2,3,4]\n",
    "accuracy_test_data=[svm[\"test_set\"],decision[\"test_set\"],kmean[\"test_set\"],neural[\"test_set\"]]\n",
    "LABELS=[\"SVM\",\"Decision-Tree\",\"K-Mean\",\"Neural-net\"]\n",
    "\n",
    "plt.bar(classifier,accuracy_test_data,align='center')\n",
    "plt.xticks(classifier, LABELS) #binding label with x axis data\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Analysis with 2 Class')\n",
    "plt.show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
